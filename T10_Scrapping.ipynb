{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5oDYHUm8fFe1m3ud6YuwE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akusiapa15/tugas10_scraping/blob/main/T10_Scrapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx6ZsvrqgYh9",
        "outputId": "f18315a2-344a-4c6a-9b82-0a5816cbe0de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ],
      "source": [
        "pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from csv import writer\n",
        "\n",
        "# URL to scrape\n",
        "url = \"https://www.superindo.co.id/hubungi-kami/lokasi-superindo\"\n",
        "res = requests.get(url)\n",
        "html = BeautifulSoup(res.content, \"html.parser\")\n",
        "\n",
        "# Lists to hold locations and addresses\n",
        "lokasi_superindo = []\n",
        "alamat_superindo = []\n",
        "\n",
        "# Find all store details\n",
        "for item in html.find_all(\"div\", class_=\"col-md-4 col-xs-12 none-space store_detail\"):\n",
        "    lokasi = item.find(\"p\", class_=\"red standar-font space\").text.strip()\n",
        "    alamat = item.find(\"p\", class_=\"standar-font none-space\").text.strip()\n",
        "    lokasi_superindo.append(lokasi)\n",
        "    alamat_superindo.append(alamat)\n",
        "\n",
        "# Combine lokasi and alamat into a single list of tuples\n",
        "data = list(zip(lokasi_superindo, alamat_superindo))\n",
        "\n",
        "# Write to CSV\n",
        "with open('/content/sample_data/lokasi_superindo1.csv', 'w', newline='', encoding='utf-8') as csv_file:\n",
        "    csv_writer = writer(csv_file)\n",
        "    headers = ['Lokasi', 'Alamat']\n",
        "    csv_writer.writerow(headers)\n",
        "\n",
        "    for lokasi, alamat in data:\n",
        "        csv_writer.writerow([lokasi, alamat])"
      ],
      "metadata": {
        "id": "-opbM4-is_wB"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}